{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Implementation.ipynb",
      "provenance": [],
      "mount_file_id": "1f2Ij4hSMrsRphv00LIFT9ykMNmnr0PgX",
      "authorship_tag": "ABX9TyPLf8E0dPkCuVIIp0Nh+MyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SedimentaryRockStar/MNIST_Kaggle_Competition/blob/main/CNN_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxjrMNuGJ9ow"
      },
      "source": [
        "#Packages we are using\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Rescaling\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "eaPyvg1a2iCY",
        "outputId": "a9b06731-3b27-4adf-d230-d1bc3475003a"
      },
      "source": [
        "\n",
        "train_images= np.load('train_images.npy')\n",
        "train_labels= pd.read_csv('/content/train_labels.csv')\n",
        "test_images= np.load('/content/test_images.npy', allow_pickle= True)\n",
        "test_labels= pd.read_csv('/content/sample_submission.csv')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a43837027d28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/train_labels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test_images.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 14540768 into shape (50000,28,28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "014zdP9VPBYY"
      },
      "source": [
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "\n",
        "\n",
        "input_shape= X_train[0].shape # Regulate the input sizes for all the layers"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvi7SIoPPg3N",
        "outputId": "3562efb9-893b-4b37-c372-4b323a8bace0"
      },
      "source": [
        "print(X_train.shape)\n",
        "model= Sequential() \n",
        "model. add(Rescaling(scale=1./255)) # Rescale all the data\n",
        "model. add(Conv2D(filters= 32, kernel_size= (3, 3), kernel_initializer= 'he_normal' , activation= 'relu', input_shape= input_shape)) # One \n",
        "model. add(Conv2D(filters= 64, kernel_size= (3, 3), activation= 'relu'))\n",
        "model. add(MaxPooling2D((2, 2))) # Maxing pooling to reduce the dimensions\n",
        "model. add(Dropout(0.20)) # Drop out 20% of the neurons to avoid overfitting\n",
        "\n",
        "model. add(Flatten()) # Flatten the images to pass into the dense layer\n",
        "model. add(Dense(128, activation= 'relu'))\n",
        "model. add(Dropout(0.2))\n",
        "model. add(Dense(10, activation= 'softmax'))\n",
        "model. compile(optimizer= \"adam\", loss= \"sparse_categorical_crossentropy\", metrics=['accuracy'] ) # \"adam\" default optimizer\n",
        "model.fit(X_train, y_train, epochs= 10)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 177s 94ms/step - loss: 0.3720 - accuracy: 0.8664\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 175s 93ms/step - loss: 0.2358 - accuracy: 0.9141\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 172s 92ms/step - loss: 0.1860 - accuracy: 0.9320\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 173s 92ms/step - loss: 0.1523 - accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 182s 97ms/step - loss: 0.1260 - accuracy: 0.9526\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 174s 93ms/step - loss: 0.1053 - accuracy: 0.9610\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 173s 92ms/step - loss: 0.0876 - accuracy: 0.9675\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 172s 92ms/step - loss: 0.0764 - accuracy: 0.9712\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 171s 91ms/step - loss: 0.0703 - accuracy: 0.9737\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.0597 - accuracy: 0.9779\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3549898fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO5QPsQ1Rz5T",
        "outputId": "933ce25e-8454-4ec1-d447-c97104ba5ca6"
      },
      "source": [
        "val_loss, val_acc= model.evaluate(X_test, y_test)\n",
        "print(val_loss, val_acc)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3002 - accuracy: 0.9290\n",
            "0.3002329468727112 0.9290000200271606\n"
          ]
        }
      ]
    }
  ]
}